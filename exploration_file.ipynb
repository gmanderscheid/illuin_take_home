{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import unidecode\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_table = str.maketrans(string.punctuation+string.ascii_uppercase,\" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "my_stopwords = stopwords.words('english')\n",
    "my_stopwords.extend(['', ' '])\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_file(filename):\n",
    "    df = pd.read_json(filename)\n",
    "    rows = []\n",
    "    for subject in df['data']:\n",
    "        subject_rows = []\n",
    "        for paragraph in subject['paragraphs']:\n",
    "            context = [paragraph['context']]\n",
    "            questions = [question['question'] for question in paragraph['qas']]\n",
    "            context.extend(questions)\n",
    "            subject_rows.append(context)\n",
    "        rows.append(subject_rows)\n",
    "        \n",
    "    classified = pd.DataFrame(rows)\n",
    "\n",
    "    all_questions = []\n",
    "\n",
    "    for paragraph in classified.columns:\n",
    "        for questions in classified[paragraph]:\n",
    "            try : \n",
    "                context = questions[0] \n",
    "                for question in questions[1:] :\n",
    "                    all_questions.append([question, context])\n",
    "            except : \n",
    "                pass \n",
    "\n",
    "    return pd.DataFrame(all_questions, columns = ['question', 'correct_context'])\n",
    "\n",
    "def get_cosin_sim(question, contexts):\n",
    "    cos_sim_for_question = []\n",
    "    for context in contexts :\n",
    "        cv = CountVectorizer(stop_words=my_stopwords, lowercase=False)\n",
    "        matrix = cv.fit_transform(pd.DataFrame([question, context])[0]).toarray()\n",
    "        cos_sim = dot(matrix[0], matrix[1])/(norm(matrix[0])*norm(matrix[1]))\n",
    "        cos_sim_for_question.append(cos_sim)\n",
    "    return pd.Series(cos_sim_for_question)\n",
    "\n",
    "def stem_text(text):\n",
    "    return ps.stem(unidecode.unidecode(text.translate(translation_table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_file('./data/train-v2.0.json').to_csv('./data/train.csv', index=False)\n",
    "preprocess_file('./data/dev-v2.0.json').to_csv('./data/validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "validation = pd.read_csv('data/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_questions'] = df.question.apply(stem_text)\n",
    "df['processed_context'] = df.correct_context.apply(stem_text)\n",
    "validation['processed_questions'] = validation.question.apply(stem_text)\n",
    "validation['processed_context'] = validation.correct_context.apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = df.processed_questions.loc[0]\n",
    "contexts = df.processed_context.drop_duplicates()\n",
    "\n",
    "train_cosin = get_cosin_sim(question, contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = validation.processed_questions.loc[0]\n",
    "contexts = validation.processed_context.drop_duplicates()\n",
    "\n",
    "validate_cosin = get_cosin_sim(question, contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5226    the normans were in contact with england from ...\n",
      "Name: processed_context, dtype: object\n"
     ]
    }
   ],
   "source": [
    "strongest_cosin_id = validate_cosin[validate_cosin == validate_cosin.max()].index\n",
    "print(validation.processed_context.drop_duplicates().iloc[strongest_cosin_id])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b43b69dd6f25b59ac8aaf0228e8c2f5c6c732f8b6b6659a7ac713c57be84aeda"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
